{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()  # Runs Python's garbage collector\n",
    "torch.cuda.empty_cache()  # Clears PyTorch's cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast  # for list-like labels, if needed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import (\n",
    "    DebertaTokenizer,\n",
    "    DebertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and balancing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Data Preparation and Tokenization\n",
    "# -------------------------------\n",
    "\n",
    "# Define column names and load datasets\n",
    "columns = ['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label']\n",
    "df_texts = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\", header=None, names=columns)\n",
    "df_labels = pd.read_csv(\"train_semeval_parids-labels.csv\")\n",
    "\n",
    "# Ensure the IDs are strings for merging\n",
    "df_texts[\"par_id\"] = df_texts[\"par_id\"].astype(str)\n",
    "df_labels[\"par_id\"] = df_labels[\"par_id\"].astype(str)\n",
    "\n",
    "# Drop unnecessary label column from df_labels and create binary labels in df_texts\n",
    "df_labels = df_labels.drop(columns=[\"label\"])\n",
    "df_texts[\"binary_label\"] = df_texts[\"label\"].apply(lambda x: 1 if x >= 2 else 0)\n",
    "df_texts = df_texts.drop(columns=[\"label\"])\n",
    "\n",
    "# Merge datasets on paragraph ID and rename the binary label to \"label\"\n",
    "df = df_labels.merge(df_texts, on=\"par_id\", how=\"left\")\n",
    "df.rename(columns={\"binary_label\": \"label\"}, inplace=True)\n",
    "df = df.dropna(subset=[\"text\", \"label\"])  # Drop rows with missing data\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "#     text = re.sub(r\"[^a-zA-Z0-9.,!?'\\\"]\", \" \", text)  # Remove special characters\n",
    "#     return text.strip()\n",
    "\n",
    "# # Ensure text column has no NaN values before applying text cleaning\n",
    "# df[\"text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # Optionally remove only very specific noise\n",
    "    # For example, remove non-ASCII characters:\n",
    "    # text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    return text.strip()\n",
    "df[\"text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
    "print(\"Preprocessing and balancing complete!\")\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "model = DebertaForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-base\", num_labels=2, ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the texts and stack tensors\n",
    "df[\"tokenized\"] = df[\"text\"].apply(lambda x: tokenize_function(x))\n",
    "input_ids = torch.cat([t[\"input_ids\"] for t in df[\"tokenized\"]], dim=0)\n",
    "attention_masks = torch.cat([t[\"attention_mask\"] for t in df[\"tokenized\"]], dim=0)\n",
    "labels = torch.tensor(df[\"label\"].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_masks[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Create Dataset and Sampler\n",
    "# -------------------------------\n",
    "\n",
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_masks[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "# Split data into training and validation sets using indices\n",
    "indices = list(range(len(df)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ids, val_ids = input_ids[train_idx], input_ids[val_idx]\n",
    "train_masks, val_masks = attention_masks[train_idx], attention_masks[val_idx]\n",
    "train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "\n",
    "train_dataset = PCLDataset(train_ids, train_masks, train_labels)\n",
    "val_dataset = PCLDataset(val_ids, val_masks, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define Metric Computation\n",
    "# -------------------------------\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes Accuracy and F1 Score\"\"\"\n",
    "    accuracy_metric = load(\"accuracy\")\n",
    "    f1_metric = load(\"f1\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    references = eval_pred.label_ids\n",
    "    accuracy_score = accuracy_metric.compute(predictions=predictions, references=references)\n",
    "    f1_score = f1_metric.compute(predictions=predictions, references=references)\n",
    "    return {\"accuracy\": accuracy_score[\"accuracy\"], \"f1\": f1_score[\"f1\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lb124/DL_CW_2_lb124/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3350' max='3350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3350/3350 1:02:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.281439</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.357451</td>\n",
       "      <td>0.917612</td>\n",
       "      <td>0.492647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [419/419 02:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation results: {'eval_loss': 0.35745105147361755, 'eval_accuracy': 0.9176119402985075, 'eval_f1': 0.49264705882352944, 'eval_runtime': 133.5411, 'eval_samples_per_second': 12.543, 'eval_steps_per_second': 3.138, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./deberta_base_model/tokenizer_config.json',\n",
       " './deberta_base_model/special_tokens_map.json',\n",
       " './deberta_base_model/vocab.json',\n",
       " './deberta_base_model/merges.txt',\n",
       " './deberta_base_model/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Final Training with Best Hyperparameters and Early Stopping\n",
    "# -------------------------------\n",
    "\n",
    "# best_params = study.best_trial.params\n",
    "learning_rate = 7.90341162920405e-06\n",
    "weight_decay = 0.021977809081319234\n",
    "final_training_args = TrainingArguments(\n",
    "       output_dir=\"./results\",\n",
    "       learning_rate=learning_rate,\n",
    "       optim=\"adamw_torch\",\n",
    "       warmup_ratio=0.1,\n",
    "       evaluation_strategy=\"epoch\",\n",
    "       save_strategy=\"no\", # change to no\n",
    "       per_device_train_batch_size=4,  # Reduce from 8 or 16 to 4 or even 2\n",
    "       per_device_eval_batch_size=4,   # Match train batch size\n",
    "       num_train_epochs=2,\n",
    "       weight_decay=weight_decay,\n",
    "       logging_dir=\"./logs\",\n",
    "       logging_steps=50,\n",
    "       save_total_limit=2,\n",
    "       lr_scheduler_type=\"linear\",\n",
    "       load_best_model_at_end=False,\n",
    "       metric_for_best_model=\"f1\",\n",
    "       report_to=\"none\",\n",
    "       fp16=False,  # Enables mixed precision training (reduces memory usage)\n",
    "       bf16=False,  # Keep this False unless on Ampere GPUs (A100, RTX 30xx)\n",
    "   )\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=final_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "final_trainer.train()\n",
    "final_results = final_trainer.evaluate()\n",
    "print(\"Final evaluation results:\", final_results)\n",
    "\n",
    "# Save the final model and tokenizer\n",
    "model.save_pretrained(\"./deberta_base_model\")\n",
    "tokenizer.save_pretrained(\"./deberta_base_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test on dev set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/lb124/DL_CW_2_lb124/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='524' max='524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [524/524 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation results: {'eval_loss': 0.3107205927371979, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.9216435738174868, 'eval_f1': 0.4875, 'eval_runtime': 101.5281, 'eval_samples_per_second': 20.615, 'eval_steps_per_second': 5.161}\n"
     ]
    }
   ],
   "source": [
    "model = DebertaForSequenceClassification.from_pretrained(\"./deberta_base_model\")\n",
    "tokenizer = DebertaTokenizer.from_pretrained(\"./deberta_base_model\")\n",
    "columns = ['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label']\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "df_dev = pd.read_csv(\"dev_semeval_parids-labels.csv\")\n",
    "df_texts = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\", header=None, names=columns)\n",
    "\n",
    "df_dev[\"par_id\"] = df_dev[\"par_id\"].astype(str)\n",
    "df_texts[\"par_id\"] = df_texts[\"par_id\"].astype(str)\n",
    "\n",
    "df_dev = df_dev.drop(columns=[\"label\"])\n",
    "df_texts[\"binary_label\"] = df_texts[\"label\"].apply(lambda x: 1 if x >= 2 else 0)\n",
    "df_texts = df_texts.drop(columns=[\"label\"])\n",
    "\n",
    "# Merge datasets on paragraph ID and rename the binary label to \"label\"\n",
    "df_dev = df_dev.merge(df_texts, on=\"par_id\", how=\"left\")\n",
    "df_dev.rename(columns={\"binary_label\": \"label\"}, inplace=True)\n",
    "df_dev = df_dev.dropna(subset=[\"text\", \"label\"])  # Drop rows with missing data\n",
    "\n",
    "df_dev = df_dev.dropna(subset=[\"text\", \"label\"])\n",
    "def clean_text(text):\n",
    "    # text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "    # text = re.sub(r\"[^a-zA-Z0-9.,!?'\\\"]\", \" \", text)  # Remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# Ensure text column has no NaN values before applying text cleaning\n",
    "df_dev[\"text\"] = df_dev[\"text\"].astype(str).apply(clean_text)\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the texts and stack tensors\n",
    "df_dev[\"tokenized\"] = df_dev[\"text\"].apply(lambda x: tokenize_function(x))\n",
    "\n",
    "dev_input_ids = torch.cat([t[\"input_ids\"] for t in df_dev[\"tokenized\"]], dim=0)\n",
    "dev_attention_masks = torch.cat([t[\"attention_mask\"] for t in df_dev[\"tokenized\"]], dim=0)\n",
    "dev_labels = torch.tensor(df_dev[\"label\"].values, dtype=torch.long)\n",
    "\n",
    "df_dev[\"tokenized\"] = df_dev[\"text\"].apply(lambda x: tokenize_function(x))\n",
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_masks[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "# Create a Dataset instance (assuming you have a PCLDataset defined similarly)\n",
    "dev_dataset = PCLDataset(dev_input_ids, dev_attention_masks, dev_labels)\n",
    "learning_rate = 7.90341162920405e-06\n",
    "weight_decay = 0.021977809081319234\n",
    "final_training_args = TrainingArguments(\n",
    "       output_dir=\"./results\",\n",
    "       learning_rate=7.90341162920405e-06,\n",
    "       optim=\"adamw_torch\",\n",
    "       warmup_ratio=0.1,\n",
    "       evaluation_strategy=\"epoch\",\n",
    "       save_strategy=\"no\", # change to no\n",
    "       per_device_train_batch_size=4,  # Reduce from 8 or 16 to 4 or even 2\n",
    "       per_device_eval_batch_size=4,   # Match train batch size\n",
    "       num_train_epochs=2,\n",
    "       weight_decay=0.021977809081319234,\n",
    "       logging_dir=\"./logs\",\n",
    "       logging_steps=50,\n",
    "       save_total_limit=2,\n",
    "       lr_scheduler_type=\"linear\",\n",
    "       load_best_model_at_end=False,\n",
    "       metric_for_best_model=\"f1\",\n",
    "       report_to=\"none\",\n",
    "       fp16=False,  # Enables mixed precision training (reduces memory usage)\n",
    "       bf16=False,  # Keep this False unless on Ampere GPUs (A100, RTX 30xx)\n",
    "   )\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=final_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "final_results = final_trainer.evaluate()\n",
    "print(\"Final evaluation results:\", final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
