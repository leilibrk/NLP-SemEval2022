{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar  2 08:54:24 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A30                     Off |   00000000:02:00.0 Off |                   On |\n",
            "| N/A   30C    P0             26W /  165W |      51MiB /  24576MiB |     N/A      Default |\n",
            "|                                         |                        |              Enabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| MIG devices:                                                                            |\n",
            "+------------------+----------------------------------+-----------+-----------------------+\n",
            "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|      Shared           |\n",
            "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
            "|                  |                                  |        ECC|                       |\n",
            "|==================+==================================+===========+=======================|\n",
            "|  0    1   0   0  |              26MiB / 11968MiB    | 28      0 |  2   0    2    0    0 |\n",
            "|                  |                 0MiB / 16383MiB  |           |                       |\n",
            "+------------------+----------------------------------+-----------+-----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (1.15.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1WIr4KP9qw4",
        "outputId": "05ef9704-75d7-4ea4-b7ff-5591d10565ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
            "Requirement already satisfied: aiohttp in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FspblTK_9tGD",
        "outputId": "d2608ce7-2bbe-42cc-97c2-dbe8c4df4e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0wgQDE9aRS6z"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "import pandas as pd\n",
        "import ast  # for list-like labels, if needed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from transformers import (\n",
        "    DebertaTokenizer,\n",
        "    DebertaForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "import optuna  # Using optuna for hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q60ItpMsRVbN"
      },
      "outputs": [],
      "source": [
        "# Clean up GPU memory\n",
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "60fNVmas_HtR"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUoJtrdNRXvK",
        "outputId": "7615ca49-3022-4e43-f354-5e2b5ea8475b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing and balancing complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# Data Preparation and Tokenization\n",
        "# -------------------------------\n",
        "\n",
        "# Define column names and load datasets\n",
        "columns = ['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label']\n",
        "df_texts = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\", header=None, names=columns)\n",
        "df_labels = pd.read_csv(\"train_semeval_parids-labels.csv\")\n",
        "\n",
        "# Ensure the IDs are strings for merging\n",
        "df_texts[\"par_id\"] = df_texts[\"par_id\"].astype(str)\n",
        "df_labels[\"par_id\"] = df_labels[\"par_id\"].astype(str)\n",
        "\n",
        "# Drop unnecessary label column from df_labels and create binary labels in df_texts\n",
        "df_labels = df_labels.drop(columns=[\"label\"])\n",
        "df_texts[\"binary_label\"] = df_texts[\"label\"].apply(lambda x: 1 if x >= 2 else 0)\n",
        "df_texts = df_texts.drop(columns=[\"label\"])\n",
        "\n",
        "# Merge datasets on paragraph ID and rename the binary label to \"label\"\n",
        "df = df_labels.merge(df_texts, on=\"par_id\", how=\"left\")\n",
        "df.rename(columns={\"binary_label\": \"label\"}, inplace=True)\n",
        "df = df.dropna(subset=[\"text\", \"label\"])  # Drop rows with missing data\n",
        "\n",
        "# def clean_text(text):\n",
        "#     text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
        "#     text = re.sub(r\"[^a-zA-Z0-9.,!?'\\\"]\", \" \", text)  # Remove special characters\n",
        "#     return text.strip()\n",
        "\n",
        "# # Ensure text column has no NaN values before applying text cleaning\n",
        "# df[\"text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
        "\n",
        "def clean_text(text):\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # Optionally remove only very specific noise\n",
        "    # For example, remove non-ASCII characters:\n",
        "    # text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    return text.strip()\n",
        "df[\"text\"] = df[\"text\"].astype(str).apply(clean_text)\n",
        "print(\"Preprocessing and balancing complete!\")\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "model = DebertaForSequenceClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\", num_labels=2, ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenize the texts and stack tensors\n",
        "df[\"tokenized\"] = df[\"text\"].apply(lambda x: tokenize_function(x))\n",
        "input_ids = torch.cat([t[\"input_ids\"] for t in df[\"tokenized\"]], dim=0)\n",
        "attention_masks = torch.cat([t[\"attention_mask\"] for t in df[\"tokenized\"]], dim=0)\n",
        "labels = torch.tensor(df[\"label\"].values, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U6gNYw2iRcub"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Create Dataset and Sampler\n",
        "# -------------------------------\n",
        "\n",
        "class PCLDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_masks[idx],\n",
        "            \"labels\": self.labels[idx],\n",
        "        }\n",
        "\n",
        "# Split data into training and validation sets using indices\n",
        "indices = list(range(len(df)))\n",
        "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "train_ids, val_ids = input_ids[train_idx], input_ids[val_idx]\n",
        "train_masks, val_masks = attention_masks[train_idx], attention_masks[val_idx]\n",
        "train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
        "\n",
        "train_dataset = PCLDataset(train_ids, train_masks, train_labels)\n",
        "val_dataset = PCLDataset(val_ids, val_masks, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P069e__fRfti"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# -------------------------------\n",
        "# Perform Oversampling on the Training Set\n",
        "# -------------------------------\n",
        "\n",
        "# Create a DataFrame for the training data\n",
        "train_data = pd.DataFrame({\n",
        "    \"input_ids\": train_ids.tolist(),\n",
        "    \"attention_masks\": train_masks.tolist(),\n",
        "    \"labels\": train_labels.tolist()\n",
        "})\n",
        "\n",
        "# Separate the minority and majority classes\n",
        "minority_class = train_data[train_data[\"labels\"] == 1]\n",
        "majority_class = train_data[train_data[\"labels\"] == 0]\n",
        "\n",
        "# Upsample minority class\n",
        "minority_upsampled = resample(\n",
        "    minority_class,\n",
        "    replace=True,  # Sample with replacement\n",
        "    n_samples=len(majority_class),  # To match the majority class\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Combine majority class with the upsampled minority class\n",
        "train_data_oversampled = pd.concat([majority_class, minority_upsampled])\n",
        "\n",
        "# Shuffle the oversampled dataset\n",
        "train_data_oversampled = train_data_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Extract the oversampled training data back into input_ids, attention_masks, and labels\n",
        "train_ids_resampled = torch.tensor(train_data_oversampled[\"input_ids\"].tolist())\n",
        "train_masks_resampled = torch.tensor(train_data_oversampled[\"attention_masks\"].tolist())\n",
        "train_labels_resampled = torch.tensor(train_data_oversampled[\"labels\"].tolist())\n",
        "\n",
        "# Create the resampled dataset\n",
        "train_dataset_resampled = PCLDataset(train_ids_resampled, train_masks_resampled, train_labels_resampled)\n",
        "val_dataset = PCLDataset(val_ids, val_masks, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1oMq4ZtKRiVi"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Define Metric Computation\n",
        "# -------------------------------\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes Accuracy and F1 Score\"\"\"\n",
        "    accuracy_metric = load(\"accuracy\")\n",
        "    f1_metric = load(\"f1\")\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    references = eval_pred.label_ids\n",
        "    accuracy_score = accuracy_metric.compute(predictions=predictions, references=references)\n",
        "    f1_score = f1_metric.compute(predictions=predictions, references=references)\n",
        "    return {\"accuracy\": accuracy_score[\"accuracy\"], \"f1\": f1_score[\"f1\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fS6F2twKRksF",
        "outputId": "fcadaaff-6f1e-4dc6-e7c2-36ca9d1c630a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-25 19:02:31,397] A new study created in memory with name: no-name-cdcbdffa-b146-45e8-81ed-5166999a7a04\n",
            "/vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6074' max='6074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6074/6074 1:48:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.269300</td>\n",
              "      <td>0.557898</td>\n",
              "      <td>0.890149</td>\n",
              "      <td>0.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.040200</td>\n",
              "      <td>0.620602</td>\n",
              "      <td>0.918806</td>\n",
              "      <td>0.558442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [419/419 02:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-25 20:53:44,442] Trial 0 finished with value: 0.5584415584415584 and parameters: {'learning_rate': 8.28712997391875e-06, 'weight_decay': 0.15278837974836498}. Best is trial 0 with value: 0.5584415584415584.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial completed with F1: 0.5584415584415584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6074' max='6074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6074/6074 1:48:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029800</td>\n",
              "      <td>0.797172</td>\n",
              "      <td>0.912836</td>\n",
              "      <td>0.549383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.861862</td>\n",
              "      <td>0.917612</td>\n",
              "      <td>0.517483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [419/419 02:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-25 22:44:43,493] Trial 1 finished with value: 0.5174825174825175 and parameters: {'learning_rate': 1.232471077113667e-06, 'weight_decay': 0.11837821610641207}. Best is trial 0 with value: 0.5584415584415584.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial completed with F1: 0.5174825174825175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6074' max='6074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6074/6074 1:48:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.132100</td>\n",
              "      <td>0.651439</td>\n",
              "      <td>0.912836</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.761058</td>\n",
              "      <td>0.917015</td>\n",
              "      <td>0.501792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [419/419 02:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-26 00:35:47,278] Trial 2 finished with value: 0.5017921146953405 and parameters: {'learning_rate': 2.0041958513416804e-05, 'weight_decay': 0.15348649731418104}. Best is trial 0 with value: 0.5584415584415584.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial completed with F1: 0.5017921146953405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6074' max='6074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6074/6074 1:48:47, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.976531</td>\n",
              "      <td>0.920597</td>\n",
              "      <td>0.523297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.046130</td>\n",
              "      <td>0.918209</td>\n",
              "      <td>0.519298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='419' max='419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [419/419 02:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-26 02:26:49,179] Trial 3 finished with value: 0.519298245614035 and parameters: {'learning_rate': 3.1945503991827538e-06, 'weight_decay': 0.25145094924062084}. Best is trial 0 with value: 0.5584415584415584.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial completed with F1: 0.519298245614035\n",
            "Best hyperparameters: {'learning_rate': 8.28712997391875e-06, 'weight_decay': 0.15278837974836498}\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# Define the Hyperparameter Tuning Objective\n",
        "# -------------------------------\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters (updated to use suggest_float with log=True)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0, 0.3)\n",
        "\n",
        "    # Update TrainingArguments with trial hyperparameters\n",
        "    training_args = TrainingArguments(\n",
        "       output_dir=\"./results\",\n",
        "       learning_rate=learning_rate,\n",
        "       optim=\"adamw_torch\",\n",
        "       warmup_ratio=0.1,\n",
        "       evaluation_strategy=\"epoch\",\n",
        "       save_strategy=\"no\", # change to no\n",
        "       per_device_train_batch_size=4,  # Reduce from 8 or 16 to 4 or even 2\n",
        "       per_device_eval_batch_size=4,   # Match train batch size\n",
        "       num_train_epochs=2,\n",
        "       weight_decay=weight_decay,\n",
        "       logging_dir=\"./logs\",\n",
        "       logging_steps=50,\n",
        "       save_total_limit=2,\n",
        "       lr_scheduler_type=\"linear\",\n",
        "       load_best_model_at_end=False,\n",
        "       metric_for_best_model=\"f1\",\n",
        "       report_to=\"none\",\n",
        "       fp16=False,  # Enables mixed precision training (reduces memory usage)\n",
        "       bf16=False,  # Keep this False unless on Ampere GPUs (A100, RTX 30xx)\n",
        "   )\n",
        "\n",
        "\n",
        "    # Initialize Trainer with early stopping callback\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset_resampled,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    trainer.train()\n",
        "    eval_result = trainer.evaluate()\n",
        "\n",
        "    # Use F1 score as the objective to maximize\n",
        "    f1 = eval_result[\"eval_f1\"]\n",
        "    print(f\"Trial completed with F1: {f1}\")\n",
        "    return f1\n",
        "\n",
        "# -------------------------------\n",
        "# Run Hyperparameter Tuning with Optuna\n",
        "# -------------------------------\n",
        "\n",
        "# Create a study that maximizes the F1 score\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "# Run the optimization for a fixed number of trials \n",
        "study.optimize(objective, n_trials=4)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best hyperparameters:\", study.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluating on official dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2094\n"
          ]
        }
      ],
      "source": [
        "columns = ['par_id', 'art_id', 'keyword', 'country_code', 'text', 'label']\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "df_dev = pd.read_csv(\"dev_semeval_parids-labels.csv\")\n",
        "df_texts = pd.read_csv(\"dontpatronizeme_pcl.tsv\", sep=\"\\t\", header=None, names=columns)\n",
        "\n",
        "df_dev[\"par_id\"] = df_dev[\"par_id\"].astype(str)\n",
        "df_texts[\"par_id\"] = df_texts[\"par_id\"].astype(str)\n",
        "\n",
        "df_dev = df_dev.drop(columns=[\"label\"])\n",
        "df_texts[\"binary_label\"] = df_texts[\"label\"].apply(lambda x: 1 if x >= 2 else 0)\n",
        "df_texts = df_texts.drop(columns=[\"label\"])\n",
        "\n",
        "# Merge datasets on paragraph ID and rename the binary label to \"label\"\n",
        "df_dev = df_dev.merge(df_texts, on=\"par_id\", how=\"left\")\n",
        "df_dev.rename(columns={\"binary_label\": \"label\"}, inplace=True)\n",
        "\n",
        "#DON'T DROP\n",
        "#df_dev = df_dev.dropna(subset=[\"text\", \"label\"])  # Drop rows with missing data\n",
        "df_dev[\"text\"] = df_dev[\"text\"].fillna(\"\")\n",
        "\n",
        "print(len(df_dev))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
        "    #text = re.sub(r\"[^a-zA-Z0-9.,!?'\\\"]\", \" \", text)  # Remove special characters\n",
        "    return text.strip()\n",
        "\n",
        "# Ensure text column has no NaN values before applying text cleaning\n",
        "df_dev[\"text\"] = df_dev[\"text\"].astype(str).apply(clean_text)\n",
        "def tokenize_function(text):\n",
        "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenize the texts and stack tensors\n",
        "df_dev[\"tokenized\"] = df_dev[\"text\"].apply(lambda x: tokenize_function(x))\n",
        "\n",
        "dev_input_ids = torch.cat([t[\"input_ids\"] for t in df_dev[\"tokenized\"]], dim=0)\n",
        "dev_attention_masks = torch.cat([t[\"attention_mask\"] for t in df_dev[\"tokenized\"]], dim=0)\n",
        "dev_labels = torch.tensor(df_dev[\"label\"].values, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Create a Dataset instance (assuming you have a PCLDataset defined similarly)\n",
        "dev_dataset = PCLDataset(dev_input_ids, dev_attention_masks, dev_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/bitbucket/msd24/dlenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='524' max='524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [524/524 02:45]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final evaluation results: {'eval_loss': 0.32855427265167236, 'eval_model_preparation_time': 0.0027, 'eval_accuracy': 0.9230769230769231, 'eval_f1': 0.5360230547550432, 'eval_runtime': 166.6208, 'eval_samples_per_second': 12.561, 'eval_steps_per_second': 3.145}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = DebertaForSequenceClassification.from_pretrained(\"./deberta_oversampling_model_new\")\n",
        "tokenizer = DebertaTokenizer.from_pretrained(\"./deberta_oversampling_model_new\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Final Training with Best Hyperparameters and Early Stopping\n",
        "# -------------------------------\n",
        "\n",
        "final_training_args = TrainingArguments(\n",
        "       output_dir=\"./results\",\n",
        "       learning_rate=8.28712997391875e-06,\n",
        "       optim=\"adamw_torch\",\n",
        "       warmup_ratio=0.1,\n",
        "       evaluation_strategy=\"epoch\",\n",
        "       save_strategy=\"no\", # change to no\n",
        "       per_device_train_batch_size=4,  # Reduce from 8 or 16 to 4 or even 2\n",
        "       per_device_eval_batch_size=4,   # Match train batch size\n",
        "       num_train_epochs=2,\n",
        "       weight_decay=0.15278837974836498,\n",
        "       logging_dir=\"./logs\",\n",
        "       logging_steps=50,\n",
        "       save_total_limit=2,\n",
        "       lr_scheduler_type=\"linear\",\n",
        "       load_best_model_at_end=False,\n",
        "       metric_for_best_model=\"f1\",\n",
        "       report_to=\"none\",\n",
        "       fp16=False,  # Enables mixed precision training (reduces memory usage)\n",
        "       bf16=False,  # Keep this False unless on Ampere GPUs (A100, RTX 30xx)\n",
        "   )\n",
        "\n",
        "final_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=final_training_args,\n",
        "    train_dataset=train_dataset_resampled,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")\n",
        "\n",
        "#final_trainer.train()\n",
        "final_results = final_trainer.evaluate()\n",
        "print(\"Final evaluation results:\", final_results)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
